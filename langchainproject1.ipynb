{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries\n",
    "\n",
    "import openai\n",
    "import langchain\n",
    "import pinecone\n",
    "import pypdf\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets Read the document\n",
    "def read_doc(directory):\n",
    "    loader =PyPDFLoader(directory)\n",
    "    docs = loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = read_doc('budget_speech.pdf')\n",
    "\n",
    "# Extract only text from the document\n",
    "doc_texts = [d.page_content for d in doc]\n",
    "\n",
    "# Now print only text (optional)\n",
    "print(doc_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import IPython.display as display\n",
    "\n",
    "# Function to save metadata\n",
    "def save_metadata(data, filename=\"LANGCHAINPROJECT1metadata.json\"):\n",
    "    \"\"\"Save metadata to a JSON file.\"\"\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    # Clickable button to open metadata file\n",
    "    button_html = f'''\n",
    "    <a href=\"{filename}\" target=\"_blank\">\n",
    "        <button style=\"padding:10px 20px; font-size:16px; background-color:#007bff; color:white; border:none; border-radius:5px; cursor:pointer;\">\n",
    "            ðŸ“‚ Open Metadata\n",
    "        </button>\n",
    "    </a>\n",
    "    '''\n",
    "    \n",
    "    display.display(display.HTML(button_html))\n",
    "\n",
    "# âœ… Extract full metadata from all pages\n",
    "metadata = [d.metadata for d in doc]  # Extracts metadata from each document\n",
    "\n",
    "# âœ… Debugging: Print extracted metadata to check if it's complete\n",
    "print(\"Extracted Metadata:\", metadata)\n",
    "\n",
    "# âœ… Save full metadata to JSON\n",
    "metadata_dict = {\"metadata\": metadata}\n",
    "save_metadata(metadata_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide the docs into chunks\n",
    "### https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html#\n",
    "def chunk_data(docs,chunk_size=800,chunk_overlap=50):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size,chunk_overlap=chunk_overlap)\n",
    "    doc=text_splitter.split_documents(docs)\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents=chunk_data(docs=doc)\n",
    "len(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding Technique Of OPENAI as asked by Naresh Sir \n",
    "embeddings=OpenAIEmbeddings(api_key=os.environ['OPENAI_API_KEY'], model=\"text-embedding-3-small\")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = embeddings.embed_query(\"How are you?\")\n",
    "vector_length = len(vectors)  \n",
    "\n",
    "print(\"Vector length:\", vector_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Load API key from environment variable\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"Pinecone API key not found. Set it as an environment variable.\")\n",
    "\n",
    "print(f\"API Key loaded successfully: {api_key[:10]}...\")  # Display first 10 characters to verify\n",
    "\n",
    "# Create a Pinecone instance\n",
    "pc = Pinecone(api_key=api_key, environment=\"gcp-starter\")\n",
    "\n",
    "# Verify connection by listing available indexes\n",
    "print(\"Available indexes:\", pc.list_indexes().names())\n",
    "\n",
    "# Example: Create an index (if necessary)\n",
    "index_name = \"langchainvector\"\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    print(f\"Creating index: {index_name}\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # Replace with your desired dimension size\n",
    "        metric=\"euclidean\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-west-2\")  # Adjust as necessary\n",
    "    )\n",
    "\n",
    "print(\"Pinecone initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "import pinecone\n",
    "index = PineconeVectorStore.from_documents(\n",
    "    documents=doc,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cosine Similarity Retreive Results from VectorDB\n",
    "def retrieve_query(query,k=2):\n",
    "    matching_results=index.similarity_search(query,k=k)\n",
    "    return matching_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI(temperature=0.5)\n",
    "chain=load_qa_chain(llm,chain_type=\"stuff\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search answers from VectorDB\n",
    "def retrieve_answers(query):\n",
    "    doc_search=retrieve_query(query)\n",
    "    print(doc_search)\n",
    "    response=chain.run(input_documents=doc_search,question=query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_answers(query):\n",
    "    doc_search = retrieve_query(query)\n",
    "    \n",
    "    # Debugging: Check if doc_search has any documents\n",
    "    print(\"Documents Retrieved:\", doc_search)\n",
    "\n",
    "    # If no documents are retrieved, return a default message\n",
    "    if not doc_search:\n",
    "        print(\"Error: No documents found for the query.\")\n",
    "        return \"No relevant information found for your query.\"\n",
    "\n",
    "    # Run the chain only if documents are available\n",
    "    response = chain.run(input_documents=doc_search, question=query)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_query(query, k=5):\n",
    "    # Ensure the index is defined\n",
    "    global index\n",
    "    if 'index' not in globals():\n",
    "        print(\"Error: Vector database (index) is not initialized.\")\n",
    "        return []\n",
    "    \n",
    "    # Perform similarity search\n",
    "    doc_search = index.similarity_search(query, k=k)\n",
    "\n",
    "    return doc_search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_answers(query):\n",
    "    # embed answer from docu_search\n",
    "    doc_search = retrieve_query(query)\n",
    "\n",
    "    # Debugging: Check if documents are retrieved\n",
    "    if not doc_search:\n",
    "        print(\"Error: No documents found for the query.\")\n",
    "        return \"No relevant information found.\"\n",
    "\n",
    "    # Run the LLM chain only if documents are found\n",
    "    response = chain.run(input_documents=doc_search, question=query)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"Hello, world!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_query = \"Any budget for public transport, if yes tell about it in detail?\"\n",
    "answer = retrieve_answers(our_query)\n",
    "answer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
